# ============================================================================
# LiteLLM Proxy Configuration for Nodus OS ADK
# ============================================================================
# Unified AI Gateway for multiple LLM providers
# Docs: https://docs.litellm.ai/docs/proxy/configs
# ============================================================================

model_list:
  # ============================================================================
  # OpenAI Models
  # ============================================================================
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      timeout: 60
  
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      timeout: 60
  
  - model_name: gpt-4-turbo
    litellm_params:
      model: openai/gpt-4-turbo-preview
      api_key: os.environ/OPENAI_API_KEY
      timeout: 60
  
  # ============================================================================
  # OpenAI Embeddings
  # ============================================================================
  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      api_key: os.environ/OPENAI_API_KEY
      timeout: 30

  # ============================================================================
  # Google Gemini Models (via Vertex AI or AI Studio)
  # ============================================================================
  - model_name: gemini-2.0-flash-exp
    litellm_params:
      model: gemini/gemini-2.0-flash-exp
      api_key: os.environ/GEMINI_API_KEY
      timeout: 60
  
  - model_name: gemini-1.5-pro
    litellm_params:
      model: gemini/gemini-1.5-pro
      api_key: os.environ/GEMINI_API_KEY
      timeout: 60
  
  - model_name: gemini-1.5-flash
    litellm_params:
      model: gemini/gemini-1.5-flash
      api_key: os.environ/GEMINI_API_KEY
      timeout: 60

  # ============================================================================
  # Anthropic Claude Models
  # ============================================================================
  - model_name: claude-3-5-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      timeout: 60
  
  - model_name: claude-3-opus
    litellm_params:
      model: anthropic/claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
      timeout: 60
  
  - model_name: claude-3-haiku
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
      timeout: 60

  # ============================================================================
  # Groq Models (Fast Inference)
  # ============================================================================
  - model_name: whisper-1
    litellm_params:
      model: groq/whisper-large-v3
      api_key: os.environ/GROQ_API_KEY
      timeout: 30

# ============================================================================
# Router Settings
# ============================================================================
router_settings:
  routing_strategy: simple-shuffle
  model_group_alias:
    gpt-4: gpt-4o
    gemini: gemini-2.0-flash-exp
    claude: claude-3-5-sonnet
  
  # Retry settings
  num_retries: 2
  timeout: 60
  
  # Fallback models (format: [primary, fallback1, fallback2, ...])
  fallbacks:
    - gpt-4o: ["gpt-4o-mini", "gemini-2.0-flash-exp"]
    - gemini-2.0-flash-exp: ["gpt-4o-mini"]
    - claude-3-5-sonnet: ["gpt-4o", "gemini-2.0-flash-exp"]

# ============================================================================
# General Settings
# ============================================================================
general_settings:
  # Master key for proxy authentication and Admin UI login
  # Admin UI: username=admin, password=master_key
  master_key: sk-nodus-master-key
  
  # Database settings (store model config in PostgreSQL)
  database_url: postgresql://nodus:nodus_dev_password@postgres:5432/litellm_db
  
  # Langfuse integration for observability
  langfuse_public_key: ${LANGFUSE_PUBLIC_KEY}
  langfuse_secret_key: ${LANGFUSE_SECRET_KEY}
  langfuse_host: http://langfuse:3000
  
  # Callbacks for logging
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]
  
  # Rate limiting
  max_parallel_requests: 100
  
  # Budget management
  default_budget_per_key: 100.0
  
  # Enable detailed debug logs
  set_verbose: true

# ============================================================================
# LiteLLM Settings
# ============================================================================
litellm_settings:
  # Drop params not supported by specific models
  drop_params: true
  
  # Enable caching
  cache: false
  
  # Timeout settings
  request_timeout: 600
  
  # Success/failure logging
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]

# ============================================================================
# Environment Variables
# ============================================================================
# The following environment variables are expected:
# - OPENAI_API_KEY: OpenAI API key
# - ANTHROPIC_API_KEY: Anthropic API key
# - GEMINI_API_KEY: Google AI Studio API key (or GOOGLE_API_KEY)
# - LANGFUSE_PUBLIC_KEY: Langfuse public key (for observability)
# - LANGFUSE_SECRET_KEY: Langfuse secret key (for observability)
# ============================================================================
